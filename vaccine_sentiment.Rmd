---
title: "Vaccine Sentiment Analysis"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook that analyzes COVID vaccine sentiment from Twitter.  

This notebook uses the Bing and NRC Lexicons to mine text data and analyze the sentiments.

The purpose of this project is to identify and visualize the emotions of Twitter users regarding COVID-19 and the various COVID-19 vaccines. 


```{r}
# Load the packages
library(rtweet)
library(dplyr)
library(tidyr)
library(stringr)
library(tidytext)
library(textdata)
library(syuzhet)
library(ggplot2)
library(plotly)
```


```{r}
# Enter your Twitter api details
#app_name <- ''
#api_key <- ''
#api_key_secret <- ''

# authenticate 
#token <- create_token(
  #app = app_name,
  #consumer_key = api_key,
  #consumer_secret = api_key_secret
#)

# the token should be saved in rtweet
```


```{r}
# load the token
get_token()
```


```{r}
# what tweets to search for
search_item1 <- "#covid19"
search_item2 <- "#vaccine"
```


```{r}
# search for tweets
search1 <- search_tweets(
  search_item1, n=1000, include_rts=FALSE, lang="en"
)
search2 <- search_tweets(
  search_item2, n=1000, include_rts=FALSE, lang="en"
)

# turn lists into dataframes
df_search1 <- data.frame(search1)
df_search2 <- data.frame(search2)

# turn into tidy text objects
tweets.Search1 = search1 %>%
  select(screen_name, text)

tweets.Search2 = search2 %>%
  select(screen_name, text)

## clean/stem tweets
# remove http elements
tweets.Search1$stripped_text1 <- gsub("http\\S+","",tweets.Search1$text)
tweets.Search2$stripped_text2 <- gsub("http\\S+","",tweets.Search2$text)

# convert to lowercase, remove punctuation, add id to tweets
tweets.Search1_stem <- tweets.Search1 %>%
  select(stripped_text1) %>%
  unnest_tokens(word, stripped_text1)

tweets.Search2_stem <- tweets.Search2 %>%
  select(stripped_text2) %>%
  unnest_tokens(word, stripped_text2)

# remove stop words
cleaned_tweets.Search1 <- tweets.Search1_stem %>%
  anti_join(stop_words)

cleaned_tweets.Search2 <- tweets.Search2_stem %>%
  anti_join(stop_words)
```


```{r}
## top 10 word counts visualization
# in Search 1
ggplotly(
  
  cleaned_tweets.Search1 %>%
    count(word, sort=TRUE) %>%
    top_n(10) %>%
    mutate(word=reorder(word,n)) %>%
    ggplot(aes(x=word, y=n)) + 
    geom_col() +
    theme_minimal() +
    labs(x = "Count",
         y = "Unique Terms",
         title = paste0("Unique Terms in ", search_item1)) +
    coord_flip()

)
```


```{r}
## top 10 word counts visualization
# in Search 2
ggplotly(
  
  cleaned_tweets.Search2 %>%
    count(word, sort=TRUE) %>%
    top_n(10) %>%
    mutate(word=reorder(word,n)) %>%
    ggplot(aes(x=word, y=n)) + 
    geom_col() +
    theme_minimal() +
    labs(x = "Count",
         y = "Unique Terms",
         title = paste0("Unique Terms in ", search_item2)) +
    coord_flip()
  
)

```


```{r}
## bing
# in Search 1
bing_search1 = cleaned_tweets.Search1 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word,sentiment,sort=TRUE) %>%
  ungroup()

# in Search 2
bing_search2 = cleaned_tweets.Search2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word,sentiment,sort=TRUE) %>%
  ungroup()
```


```{r}
# search 1
# sentiment chart: combined
ggplotly(
  
  bing_search1 %>%
    top_n(10) %>%
    mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col() +
    theme_minimal() +
    coord_flip() +
    labs(title = paste0(search_item1, " Tweets"),
         x = NULL,
         y = "Contribution to Sentiment")
  
)
```


```{r}
# search 2
# sentiment chart: combined
ggplotly(

  bing_search2 %>%
    top_n(10) %>%
    mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col() +
    theme_minimal() +
    coord_flip() +
    labs(title = paste0(search_item2, " Tweets"),
         x = NULL,
         y = "Contribution to Sentiment")

)
```


```{r}
## nrc
# sentiment analysis
nrc_search1 <- get_nrc_sentiment(as.character(cleaned_tweets.Search1))
nrc_search2 <- get_nrc_sentiment(as.character(cleaned_tweets.Search2))

# sentiment score
nrc_score_search1 <- data.frame(colSums(nrc_search1[,]))
nrc_score_search2 <- data.frame(colSums(nrc_search2[,]))

names(nrc_score_search1) <- "Score"
nrc_score_search1 <- cbind("sentiment" = rownames(nrc_score_search1), nrc_score_search1)
rownames(nrc_score_search1) <- NULL

names(nrc_score_search2) <- "Score"
nrc_score_search2 <- cbind("sentiment" = rownames(nrc_score_search2), nrc_score_search2)
rownames(nrc_score_search2) <- NULL
```


```{r}
# visualize nrc sentiment
# Search 1
ggplotly(

  ggplot(nrc_score_search1, aes(sentiment, Score)) +
    geom_bar(aes(fill=sentiment), stat = "identity") +
    theme_minimal() +
    theme(legend.position = "none") +
    xlab("Sentiments") +
    ylab("Scores") +
    ggtitle(paste0(search_item1, " Tweets"))

)
```


```{r}
# visualize nrc sentiment
# Search 2
ggplotly(

  ggplot(nrc_score_search2, aes(sentiment, Score)) +
    geom_bar(aes(fill=sentiment), stat = "identity") +
    theme_minimal() +
    theme(legend.position = "none") +
    xlab("Sentiments") +
    ylab("Scores") +
    ggtitle(paste0(search_item2, " Tweets"))

)
```

